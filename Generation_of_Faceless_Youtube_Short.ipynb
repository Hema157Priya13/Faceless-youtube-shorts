{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install and import all necessary libraries and API's**"
      ],
      "metadata": {
        "id": "xfV0q7FlIg9y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajSLbcV6iSfC"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install elevenlabs\n",
        "import openai\n",
        "import elevenlabs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Generate a list of highlights using smart prompt (using OpenAI API)**"
      ],
      "metadata": {
        "id": "XkYVdfuRI0Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your OpenAI API key\n",
        "api_key = \"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\"\n",
        "\n",
        "# Initial prompt based on the Ramayana\n",
        "prompt = \"Generate five highlighted headings based on the Ramayana:\"\n",
        "\n",
        "# Initialize the OpenAI API client\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Generate highlighted headings\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=100,  # You can adjust this to control the length of each heading\n",
        "    n = 5  # Generate 5 headings\n",
        ")\n",
        "\n",
        "# Extract the headings from the response\n",
        "headings = [heading['text'] for heading in response.choices]\n",
        "\n",
        "# Print the generated highlighted headings\n",
        "for i, heading in enumerate(headings, 1):\n",
        "    print(f\"Heading {i}: {heading}\")\n"
      ],
      "metadata": {
        "id": "S0e0mEVqiViA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list= []\n",
        "for i in range(1,6):\n",
        "  heading_req= headings[0]\n",
        "  parts = heading_req.split('. ', i)\n",
        "  part_1 = parts[i].split('\\n')\n",
        "  list.append(part_1[0])\n",
        "print(list)\n"
      ],
      "metadata": {
        "id": "tWtprugzTXuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate prompt to generate the story**"
      ],
      "metadata": {
        "id": "SvixVqXRJ0U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial prompt based on the Ramayana\n",
        "chosen_topic = list[1]\n",
        "prompt_story = f\"Write a engaging one-paragraph in short about {chosen_topic} in the context of the Ramayana for a captivating YouTube Short.\"\n",
        "print(prompt_story)\n",
        "# Initialize the OpenAI API client\n",
        "#openai.api_key = api_key\n",
        "\n",
        "# Generate a story based on the prompt\n",
        "response_story = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=prompt_story,\n",
        "    max_tokens=200,  # You can adjust this to control the length of the story\n",
        ")\n",
        "\n",
        "story = response_story.choices[0].text.strip()\n",
        "\n",
        "# Print the generated story\n",
        "print(\"Story:\")\n",
        "print(story)"
      ],
      "metadata": {
        "id": "Q_Zwuex2S79V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the paragraph into a list of sentences\n",
        "sentences = story.split(\". \")\n",
        "\n",
        "# Print the list of sentences\n",
        "for sentence in sentences:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "id": "GYTNl0Do5zYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate images**"
      ],
      "metadata": {
        "id": "Yk7c9dVAKRoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_image= []\n",
        "for sentence in sentences:\n",
        "  # Define your text prompt for generating an image\n",
        "  text_prompt = f\"Generate image of {sentence} based on Ramayana.\"\n",
        "\n",
        "  # Specify the DALLÂ·E model and parameters\n",
        "  model = \"image-alpha-001\"\n",
        "  n = 1 # Number of images to generate\n",
        "  size = \"1024x1024\"  # YouTube Short-sized image\n",
        "\n",
        "  # Generate an image based on the text prompt\n",
        "  response_image = openai.Image.create(\n",
        "      model=model,\n",
        "      prompt=text_prompt,\n",
        "      n=n,\n",
        "      size=size\n",
        "  )\n",
        "\n",
        "  # Get the image URL\n",
        "  print(response_image)\n",
        "  # Response contains the JSON data\n",
        "  response_data = response_image\n",
        "  # Check if \"data\" is present in the response and contains at least 10 items\n",
        "  if \"data\" in response_data and len(response_data[\"data\"]) >= 1:\n",
        "      image_urls = [item[\"url\"] for item in response_data[\"data\"]]\n",
        "      for i, url in enumerate(image_urls, 1):\n",
        "          generated_image.append(url)\n",
        "          print(f\"Generated Image {i} URL:\", url)\n",
        "  else:\n",
        "      print(\"Not enough image URLs found in the response.\")"
      ],
      "metadata": {
        "id": "TB9EQ3xupsRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(generated_image)"
      ],
      "metadata": {
        "id": "yksB06Qy0Azp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7A3ucqXEOMaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_name= 'youtubeShort'\n",
        "folder_path = os.path.join('/content/drive/My Drive', folder_name)\n",
        "os.makedirs(folder_path, exist_ok= True)\n",
        "os.chdir(folder_path)"
      ],
      "metadata": {
        "id": "jtgM4hP8Od7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('story.txt', 'w') as f:\n",
        "  f.write(story)"
      ],
      "metadata": {
        "id": "CkBXkoH9PVq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name= 'audio'\n",
        "folder_path_audio = os.path.join(folder_path, folder_name)\n",
        "os.makedirs(folder_path_audio, exist_ok= True)\n",
        "os.chdir(folder_path_audio)"
      ],
      "metadata": {
        "id": "MwZ1-eOUTeCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate narration of video**"
      ],
      "metadata": {
        "id": "_CUWZxmxKysv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elevenlabs.set_api_key(\"f76df17680d22a94bdcf97845cdc995e\")\n",
        "for i in range(0,len(sentences)):\n",
        "  audio = elevenlabs.generate(\n",
        "      text= sentences[i],\n",
        "      voice = \"Bella\"\n",
        "  )\n",
        "  elevenlabs.save(audio, f\"audio_{i+1}.mp3\")"
      ],
      "metadata": {
        "id": "SSXfFMmgUZ35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install Pillow"
      ],
      "metadata": {
        "id": "AkIWGCDBgCjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name= 'images'\n",
        "folder_path_img= os.path.join(folder_path, folder_name)\n",
        "os.makedirs(folder_path_img, exist_ok= True)\n",
        "os.chdir(folder_path_img)"
      ],
      "metadata": {
        "id": "CdqBacLURU9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "for i in range(0, len(sentences)):\n",
        "  # URL of the image you want to save\n",
        "  image_url = generated_image[i]\n",
        "\n",
        "  # Send an HTTP GET request to the URL\n",
        "  response = requests.get(image_url)\n",
        "\n",
        "  # Check if the request was successful (status code 200)\n",
        "  if response.status_code == 200:\n",
        "      # Open the image from the response content\n",
        "      image = Image.open(BytesIO(response.content))\n",
        "\n",
        "      # Save the image to a file\n",
        "      image.save(f\"saved_image_{i+1}.jpg\")\n",
        "      print(f\"Image saved as 'saved_image_{i+1}.jpg'\")\n",
        "  else:\n",
        "      print(\"Failed to download the image. Status code:\", response.status_code)\n"
      ],
      "metadata": {
        "id": "E8e3QPHlgHgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "BijMwg-mV7yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name= 'Videos'\n",
        "folder_path_video = os.path.join(folder_path, folder_name)\n",
        "os.makedirs(folder_path_video, exist_ok= True)"
      ],
      "metadata": {
        "id": "KJCMt0QgWHcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add transitions to images and combine video**"
      ],
      "metadata": {
        "id": "ULPRzIVMLL0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import *\n",
        "\n",
        "def resize_func_1(t):\n",
        "        return 1 + 0.2*t  # Zoom-in.\n",
        "\n",
        "def resize_func_2(t):\n",
        "        return 1 + 0.2*t  # Stay.\n",
        "\n",
        "def resize_func_3(t):\n",
        "        #duration= 3* half_audio_duration;\n",
        "        return 1 + 0.2*(1-t)  # Zoom-out.\n"
      ],
      "metadata": {
        "id": "UUlgveIImEVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeVideoClip, ColorClip, concatenate_videoclips, vfx\n",
        "input_folder= '/content/drive/MyDrive/youtubeShort/images'\n",
        "output_folder= '/content/drive/MyDrive/youtubeShort/Videos'\n",
        "audio_folder= '/content/drive/MyDrive/youtubeShort/audio'\n",
        "for i in range(0,len(generated_image)):\n",
        "  input_image=  os.path.join(input_folder, f'saved_image_{i+1}.jpg')\n",
        "  # Load the image\n",
        "  image = VideoFileClip(input_image)\n",
        "\n",
        "# Load the audio\n",
        "  audio_path = os.path.join(audio_folder, f'audio_{i+1}.mp3')  # Replace with the path to your audio\n",
        "  audio = AudioFileClip(audio_path)\n",
        "\n",
        "  # Split the audio duration into two halves\n",
        "  audio_duration = audio.duration\n",
        "  half_audio_duration = audio_duration / 3\n",
        "  print(audio_duration)\n",
        "  print(half_audio_duration)\n",
        "  # Add the left-to-right transition for the first half of audio duration\n",
        "  if half_audio_duration > 0:\n",
        "    transition_duration = 1  # Duration of the transition\n",
        "    start_position = (0, image.h / 2)  # Starting position on the left\n",
        "    end_position = (image.w, image.h / 2)  # Ending position on the right\n",
        "\n",
        "    # Create a copy of the image and set its position to start_position\n",
        "    left_to_right_clip = image.copy().set_position(start_position)\n",
        "\n",
        "    # Animate the position to move from start_position to end_position\n",
        "    left_to_right_clip = left_to_right_clip.set_position(lambda t: (\n",
        "        start_position[0] + (end_position[0] - start_position[0]) * t,\n",
        "        start_position[1] + (end_position[1] - start_position[1]) * t\n",
        "    ))\n",
        "\n",
        "    left_to_right_clip = left_to_right_clip.set_duration(half_audio_duration)\n",
        "\n",
        "  if half_audio_duration < audio_duration:\n",
        "    clip_img = (\n",
        "      left_to_right_clip\n",
        "      .set_position(('center', 'center'))\n",
        "      .set_duration(half_audio_duration/2)\n",
        "      .set_fps(10)\n",
        "    )\n",
        "    clip_img_1 = (\n",
        "      clip_img\n",
        "      .resize(resize_func_2)\n",
        "      .set_position(('center', 'center'))\n",
        "      .set_duration(half_audio_duration/2)\n",
        "      .set_fps(25)\n",
        "    )\n",
        "    clip_img_2 = (\n",
        "      clip_img_1  # Use the same clip_img_1 as a base\n",
        "      .resize(resize_func_3)  # Apply zoom-out resizing function\n",
        "      .set_duration(half_audio_duration)  # Keep the same duration\n",
        "    )\n",
        "\n",
        "  # Concatenate the video clips with transitions\n",
        "  if half_audio_duration > 0 and half_audio_duration < audio_duration:\n",
        "      final_video = CompositeVideoClip([left_to_right_clip, clip_img, clip_img_1, clip_img_2]).set_audio(audio)\n",
        "  else:\n",
        "      final_video = image.set_audio(audio)\n",
        "\n",
        "  # Export the final video\n",
        "  output_path = os.path.join(output_folder, f'combined_video_with_transitions{i+1}.mp4')\n",
        "  final_video.write_videofile(output_path, codec='libx264')\n",
        "\n",
        "  print(\"Video with transitions saved to\", output_path)"
      ],
      "metadata": {
        "id": "UgLG3XrMajRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_paths= []\n",
        "for i in range(0,len(generated_image)):\n",
        "  output_path = os.path.join(output_folder, f'combined_video_with_transitions{i+1}.mp4')\n",
        "  video_paths.append(output_path)\n",
        "\n",
        "# Load the video clips\n",
        "video_clips = [VideoFileClip(video_path) for video_path in video_paths]\n",
        "\n",
        "# Concatenate the video clips\n",
        "final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
        "\n",
        "# Export the final video\n",
        "output_path = os.path.join(output_folder,'combined_video.mp4')  # Replace with the desired output file path\n",
        "final_video.write_videofile(output_path, codec='libx264')"
      ],
      "metadata": {
        "id": "Sc-CYjGhzODi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add captions to the youtube short**"
      ],
      "metadata": {
        "id": "FuVa_FOHLVY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "# Define your API key and template ID\n",
        "API_KEY = 'bb_pr_762111ef4700de01e89b64101b0ab9'\n",
        "TEMPLATE_ID = 'egL3lAz8Vq29Ma7Rpj'\n",
        "\n",
        "# Encode the input_media_url\n",
        "input_media_url = \"https://drive.usercontent.google.com/download?id=1-to8yRostGRUU4XaEyHdv_btVISKa27b&export=download&authuser=0&confirm=t&uuid=f14b4ff1-e70b-4c03-8f37-a96234090ad1&at=APZUnTXDhM3AVK91BRiVuYVvwSeW:1698848129056\"\n",
        "\n",
        "\n",
        "# Define the data for video rendering\n",
        "data = {\n",
        "    \"video_template\": TEMPLATE_ID,\n",
        "    \"input_media_url\": input_media_url,\n",
        "    \"modifications\": [\n",
        "        {\n",
        "            \"name\": \"avatar\",\n",
        "            \"image_url\": \"https://www.bannerbear.com/images/tools/people/82.jpg\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Define the API endpoint for video rendering\n",
        "api_endpoint = 'https://api.bannerbear.com/v2/videos'\n",
        "\n",
        "# Make a POST request to start the video rendering\n",
        "response = requests.post(api_endpoint, json=data, headers={\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Bearer {API_KEY}'\n",
        "})\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 202:\n",
        "    print(\"Video rendering request accepted. Rendering in progress.\")\n",
        "else:\n",
        "    print(\"Video rendering request failed. Status code:\", response.status_code)\n",
        "    print(\"Response content:\", response.content)\n"
      ],
      "metadata": {
        "id": "9fSqzhq_4poC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_data = response.json()\n",
        "video_uid = video_data.get(\"uid\")\n",
        "print(video_uid)"
      ],
      "metadata": {
        "id": "Ma0y8bTWBB7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a GET request to retrieve the video and check the status\n",
        "response = requests.get(api_endpoint, headers={\n",
        "    'Authorization': f'Bearer {API_KEY}'\n",
        "})\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    video_data = response.json()\n",
        "    status = video_data.get(\"status\")\n",
        "    video_url = video_data.get(\"video_url\")\n",
        "\n",
        "    while status != \"completed\":\n",
        "        if status == \"failed\":\n",
        "            print(\"Video rendering failed.\")\n",
        "            break\n",
        "\n",
        "        # Wait for a short period before checking the status again\n",
        "        time.sleep(10)\n",
        "\n",
        "        # Make a new GET request to refresh the video data\n",
        "        response = requests.get(api_endpoint, headers={\n",
        "            'Authorization': f'Bearer {API_KEY}'\n",
        "        })\n",
        "        video_data = response.json()\n",
        "        status = video_data.get(\"status\")\n",
        "        video_url = video_data.get(\"video_url\")\n",
        "\n",
        "    if status == \"completed\":\n",
        "        # Video rendering is complete, and video_url is available\n",
        "        print(\"Video rendering successful.\")\n",
        "        print(\"Video URL:\", video_url)\n",
        "else:\n",
        "    print(\"Video retrieval request failed. Status code:\", response.status_code)\n",
        "    print(\"Response content:\", response.content)"
      ],
      "metadata": {
        "id": "W2Wopg4pCzLD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}